{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following libraries are needed to excute this code:\n",
    "Keras;\n",
    "Tensorflow CPU or GPU;\n",
    "Matplotlib;\n",
    "sklearn;\n",
    "itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset: https://www.kaggle.com/chetankv/dogs-cats-images#dog%20vs%20cat.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutional Neural Networks to classify dogs and cats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and keras (to build the neural network)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Useful tools from keras to make code more legible (it is also possible to do this manually each time one requires a function) \n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "\n",
    "# Tensorflow uses numpy arrays to process data\n",
    "import numpy as np\n",
    "\n",
    "# Useflul tool for visualisation\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Useflul tool for evalutating the netwrok\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data aquirement and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to download the dataset beforehand and create \n",
    "# a blank python file named: \"weigths.py\" located in the dataset file\n",
    "# File paths: These might differ on different devices\n",
    "computer_path = '/Users/timourjavarmagnier/Downloads/dataset/'\n",
    "train_path = computer_path + 'training_set'\n",
    "test_path = computer_path + 'test_set'\n",
    "weights_path = computer_path + 'weights.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation from image\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224, 224), classes=['cats', 'dogs'], batch_size= 10)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224, 224), batch_size= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation function\n",
    "def plots(ims, figsize=(12, 6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if ims.shape[-1] != 3:\n",
    "            ims = ims.transpose((0, 2, 3, 1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims) // rows if len(ims) % 2 == 0 else len(ims) // rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i + 1)\n",
    "        sp.axis('off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the training images along with their corresponding labels\n",
    "imgs, labels = next(train_batches)\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the keras tool kits the following convolutional neural netwrok was built\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    # Convolutional layers: \n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), use_bias=True, padding='same'),\n",
    "    \n",
    "    # A ZeroPadding layer adds a layer of 0 around the image to prevent \n",
    "    # loss of information due to the convolutions. This is done by calling padding='same'\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), use_bias=True, padding='same'),\n",
    "    \n",
    "    # A maxpooling layer only recording the max pixel value of a 2 by 2 square to diminish the number of parameters\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), use_bias=True, padding='same'),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), use_bias=True, padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), use_bias=True, padding='same'),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), use_bias=True, padding='same'),\n",
    "    MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "\n",
    "    # Transforms data into a single numpy array ready to be fed to the neural network\n",
    "    Flatten(),\n",
    "\n",
    "    # Hidden layers of the neural netwrok\n",
    "    Dense(300, activation='relu'),\n",
    "    \n",
    "    # Dropouts temporarely deactivate neurons in training to prevent over-specialization\n",
    "    Dropout(0.5),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weights_path:\n",
    "    model.load_weights(weights_path)\n",
    "    print(\"Weights have been loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles the model with and Adam optimizer with a learning rate of 0.0001\n",
    "# The loss fucntion is calculated as cateforical_croseentropy\n",
    "model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the network on 10 epochs\n",
    "model.fit_generator(train_batches, steps_per_epoch=4, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches, steps=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
